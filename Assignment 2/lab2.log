Name: Jingjing Nie
UID: 304567417
Lab2 Log

1. export LC_ALL='C' to make sure that I am in the standard C

2. sort /usr/share/dict/words > words
I used it to sort the content under that directory,
 and record the sorted results to words.

3. wget http://web.cs.ucla.edu/classes/spring18/cs35L/assign/assign2.html
I used it to download the assignment HTML as a text file

4. tr -c 'A-Za-z' '[\n*]' < assign2.html
This command prints out lots of lines together with lots of empty lines. 
It turns out that only characters from 'A-Z' or 'a-z' have been printed out, 
and others have been changed to empty lines. 
This is because the comma 'tr' did the replace work. 
With the '-c' option, it changes all characters that are complement to 
the ones containing argument 'A-Za-z' to newlines.

5.tr -cs 'A-Za-z' '[\n*]' < assign2.html
This command prints out lot of lines similar as the command before does, 
but with only one empty line. This is due to the "-s" option,
which helped squeeze the output by aqueezing repeated newlines into newlines 
so that it si now easier to read the other lines.

6.tr -cs 'A-Za-z' '[\n*]' < assign2.html | sort
This command firstly produced the lines as the command above, 
and then sort the output through the pipe and 'sort' command. 
So the output was sorted alphabetically.

7.tr -cs 'A-Za-z' '[\n*]' < assign2.html | sort -u
This command produced the similar output as command 6, 
but with no repeated lines.
This is due to the option '-u' which helped keep only unique lines.

8.tr -cs 'A-Za-z' '[\n*]' < assign2.html | sort -u | comm - words
This command takes the output generated by command that is the same as 7,
and passes it into the command 'comm' using a pipe. 
'comm' then compared the output with the words file generated in step 2. 
This comparison command, produce three-column output.  
Column one contains lines unique to the output, 
column two contains lines unique to words, 
and column three contains lines common to both files.

9.tr -cs 'A-Za-z' '[\n*]' < assign2.html | sort -u | comm -23 - words
This commands performed similarly to command 8, 
but with an option "-23". 
With this option, the output ignored the 2nd and 3rd columns 
in the default output and produced only the first column, 
which describe the unique words in output from 
'tr -cs 'A-Za-z' '[\n*]' < assign2.html | sort -u'.

10.http://mauimapp.com/moolelo/hwnwdseng.htm
I used this command to download the Hawaiian language web to the text file.

11. Hawaiian words
#! /bin/bash                   
sed -n '/<td>/p' hwnwdseng.htm |
# I used this command to firstly extract all the words from the table
sed -n '2~2p' |
# To remove English words from the file by only printing out even numbered lines
sed -r 's/<td>//g' |
# I used this command to remove all '<td>' characters
sed -r 's/<\/td>//g' |
# I used this command to remove all '</td>' characters
tr '[:upper:]' '[:lower:]' |
# I used this command to change all upper case letters into lower case letters
sed -r "s/\`/\'/g" |
# I used this command to replace ` characters into ' character
sed -r 's/ /\n/g' |
# I used this command to treat spaces as new lines
sed -r '/^\s*$/d' |
# I used this command to delete empty lines
sed 's/<[^>]*>//g' |
# I used this command to remove the remaining invalid <> characters
tr -cs "pk\'mnwlhaeiou" '[\n*]' |
# To remove the invalid Hawaiian words based on its traditional orthography
sort -u
# Finally, I used this command to sort the final output

I finally granted permission to buildwords by using "chmod +x buildwords" 
and used the command "cat hwnwdseng.htm | ./buildwords | less"

To check the spellings, firstly, 
I created a Hawaiian dictionary from the words extracted eariler:
cat hwnwdseng.htm | ./buildwords > hwords

To check the spellings for English words, I used 'words' dictionary. 
I extracted letters from assign2.html,
changed the upper case letters in assign2.html first into lower case letters, 
and then sorted the output, and finally, 
as in the earlier exercises, use "comm" with the corrsponding dictionary. 
Finally, I used "wc -l" to count the mispelled words.
cat assign2.html | tr -cs 'A-Za-z' '[\n*]' | 
tr '[:upper:]' '[:lower:]' | sort -u | comm -23 - words | wc -l
It turned out that there are 39 mispelled English words.

To check the spellings for Hawaiian words, I used "hwords" dictionary. 
The commands are similar as above.
cat assign2.html | tr -cs 'A-Za-z' '[\n*]' | 
tr '[:upper:]' '[:lower:]' | sort -u | comm -23 - hwords | wc -l
It turned out that there are 406 mispelled Hawaiian words.

To check for words that are misspelled in English but not in Hawaiian, 
I used the output from the one that's checking the misspelled English words, 
and then use that output to compare with the Hawaiian dictionary.
cat assign2.html | tr -cs 'A-Za-z' '[\n*]' | 
tr '[:upper:]' '[:lower:]' | sort -u | comm -23 - words | comm -12 - hwords
The results are as follows:
halau
lau
wiki

To check for words that are misspelled in Hawaiian but not in English, 
I used the output from the one that's checking the misspelled Hawaiian words, 
and then use that output to compare with the English dictionary.
cat assign2.html | tr -cs 'A-Za-z' '[\n*]' | 
tr '[:upper:]' '[:lower:]' | sort -u | comm -23 - hwords | comm -12 - words
There are a lot of results, somce of the examples are as follows:
a
able
about
above
abovementioned
accent
address